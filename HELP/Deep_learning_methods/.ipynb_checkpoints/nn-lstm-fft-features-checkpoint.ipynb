{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import fftpack\n",
    "import xgboost\n",
    "import warnings\n",
    "from sklearn.model_selection import cross_val_predict, cross_validate\n",
    "import seaborn as sns; sns.set()\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from keras.layers import LSTM,Input,Dense,Flatten,SpatialDropout1D,Dropout,CuDNNLSTM,Reshape,Concatenate\n",
    "from keras.layers import Lambda,concatenate,BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K \n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "5babec0efc3733f041bae0477d4445846d389ac8"
   },
   "outputs": [],
   "source": [
    "directory = \"../input/\"\n",
    "X_test_path = os.path.join(directory,\"X_test.csv\")\n",
    "X_train_path = os.path.join(directory,\"X_train.csv\")\n",
    "X_test_data = pd.read_csv(X_test_path)\n",
    "X_train_data = pd.read_csv(X_train_path)\n",
    "y_train_data = pd.read_csv(os.path.join(directory,\"y_train.csv\"))\n",
    "sample_submission = pd.read_csv(os.path.join(directory,\"sample_submission.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting class labels to binary matrix representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "cd2963c2f70ea0ced58b62d99bee0104dd65ec4e"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(list(y_train_data[\"surface\"]))\n",
    "y_train_dataset_for_nn = to_categorical(le.transform(list(y_train_data[\"surface\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating X-datasets for LSTM - shape = (num_samples,128,10)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "d8b39aa58b059f4ffaa1778bcf191642b1d736ba"
   },
   "outputs": [],
   "source": [
    "def dataset_for_nn(X_dataset):\n",
    "    num_samples = X_dataset.shape[0]//128\n",
    "    X_dataset_for_nn = np.zeros((num_samples,128,10))\n",
    "    for i in range(num_samples):\n",
    "        subset = np.array(X_dataset.iloc[i*128:(i+1)*128,3:])\n",
    "        X_dataset_for_nn[i,:,:] = subset\n",
    "    return X_dataset_for_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "1afebce40741f249e46839b947ad0e1ca8d1d4e7"
   },
   "outputs": [],
   "source": [
    "X_train_for_nn = dataset_for_nn(X_train_data)\n",
    "X_test_for_nn = dataset_for_nn(X_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function for extracting Fourier transform with averaging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freqs(dataset,width):\n",
    "    X = np.abs(fftpack.fft(dataset))\n",
    "    squeezed_dataset = []\n",
    "    for i in range(64//width):\n",
    "        squeezed_dataset.append(np.mean(X[i*width:(i+1)*width]))\n",
    "    return squeezed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_features(X_dataset,width=3):\n",
    "    num_samples = len(list(set(X_dataset[\"series_id\"])))\n",
    "    num_cols = 64//width\n",
    "    features = np.zeros((num_samples,40+10*num_cols))\n",
    "    for i in range(num_samples):\n",
    "        X_train_subset = np.array(X_dataset.iloc[i*128:(i+1)*128,3:])\n",
    "        features[i,:10] = np.mean(X_train_subset,axis=0)\n",
    "        features[i,10:20] = np.std(X_train_subset,axis=0)\n",
    "        features[i,20:30] = np.max(X_train_subset,axis=0)-np.min(X_train_subset,axis=0)\n",
    "        features[i,30:40] = X_train_subset[-1,:]-X_train_subset[0,:]\n",
    "        for j in range(X_train_subset.shape[1]):\n",
    "            features[i,40+j*num_cols:40+(j+1)*num_cols] = freqs(X_train_subset[:,j],width)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features = X_features(X_train_data)\n",
    "X_test_features = X_features(X_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural network architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "89851fc4c28f0a119f0710b8ed32f102e48a2964"
   },
   "outputs": [],
   "source": [
    "def LSTM_NN(drop):\n",
    "    inp = Input(shape=(128,10))\n",
    "    x = SpatialDropout1D(0.1)(inp)\n",
    "    inp_2 = Input(shape=(250,))\n",
    "    x_2 = Dense(250, input_shape=(250,), activation=\"sigmoid\")(inp_2)\n",
    "    x_2 = Dropout(drop)(x_2)\n",
    "    x_2 = Dense(120, activation=\"sigmoid\")(x_2)\n",
    "    x_2 = Dropout(drop)(x_2)\n",
    "    x_2 = Dense(60, activation=\"sigmoid\")(x_2)\n",
    "    x_2 = Dropout(drop)(x_2)\n",
    "    x_2 = BatchNormalization()(x_2)\n",
    "    x = CuDNNLSTM(units=200, return_sequences=True, return_state=False, go_backwards=False)(x)\n",
    "    x = Dropout(drop)(x)\n",
    "    x = CuDNNLSTM(units=100, return_sequences=False, return_state=False, go_backwards=False)(x)\n",
    "    x = concatenate([x,x_2])\n",
    "    x = Dropout(drop)(x)\n",
    "    outp = Dense(9, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=[inp,inp_2], outputs=outp)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training model and prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "061e0fb6c6325f0ac84e1cea99ce819dca517223"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3044 samples, validate on 766 samples\n",
      "Epoch 1/120\n",
      " - 7s - loss: 1.9222 - val_loss: 1.7043\n",
      "Epoch 2/120\n",
      " - 2s - loss: 1.7199 - val_loss: 1.5581\n",
      "Epoch 3/120\n",
      " - 2s - loss: 1.6255 - val_loss: 1.5300\n",
      "Epoch 4/120\n",
      " - 2s - loss: 1.6070 - val_loss: 1.4744\n",
      "Epoch 5/120\n",
      " - 2s - loss: 1.5559 - val_loss: 1.4392\n",
      "Epoch 6/120\n",
      " - 2s - loss: 1.5228 - val_loss: 1.3989\n",
      "Epoch 7/120\n",
      " - 2s - loss: 1.4718 - val_loss: 1.3865\n",
      "Epoch 8/120\n",
      " - 2s - loss: 1.4240 - val_loss: 1.3068\n",
      "Epoch 9/120\n",
      " - 2s - loss: 1.4008 - val_loss: 1.3388\n",
      "Epoch 10/120\n",
      " - 2s - loss: 1.3575 - val_loss: 1.2053\n",
      "Epoch 11/120\n",
      " - 2s - loss: 1.3287 - val_loss: 1.1799\n",
      "Epoch 12/120\n",
      " - 2s - loss: 1.3400 - val_loss: 1.1765\n",
      "Epoch 13/120\n",
      " - 2s - loss: 1.3304 - val_loss: 1.1867\n",
      "Epoch 14/120\n",
      " - 2s - loss: 1.2877 - val_loss: 1.1701\n",
      "Epoch 15/120\n",
      " - 2s - loss: 1.2856 - val_loss: 1.1552\n",
      "Epoch 16/120\n",
      " - 2s - loss: 1.2712 - val_loss: 1.1498\n",
      "Epoch 17/120\n",
      " - 2s - loss: 1.2367 - val_loss: 1.1207\n",
      "Epoch 18/120\n",
      " - 2s - loss: 1.2305 - val_loss: 1.0591\n",
      "Epoch 19/120\n",
      " - 2s - loss: 1.2053 - val_loss: 1.0291\n",
      "Epoch 20/120\n",
      " - 2s - loss: 1.1735 - val_loss: 1.0584\n",
      "Epoch 21/120\n",
      " - 2s - loss: 1.1531 - val_loss: 1.0808\n",
      "Epoch 22/120\n",
      " - 2s - loss: 1.1233 - val_loss: 0.9972\n",
      "Epoch 23/120\n",
      " - 2s - loss: 1.1135 - val_loss: 1.0073\n",
      "Epoch 24/120\n",
      " - 2s - loss: 1.1266 - val_loss: 1.0098\n",
      "Epoch 25/120\n",
      " - 2s - loss: 1.0845 - val_loss: 0.9559\n",
      "Epoch 26/120\n",
      " - 2s - loss: 1.0686 - val_loss: 0.9253\n",
      "Epoch 27/120\n",
      " - 2s - loss: 1.0441 - val_loss: 0.9469\n",
      "Epoch 28/120\n",
      " - 2s - loss: 1.0450 - val_loss: 0.9481\n",
      "Epoch 29/120\n",
      " - 2s - loss: 1.0301 - val_loss: 0.9070\n",
      "Epoch 30/120\n",
      " - 2s - loss: 1.0034 - val_loss: 0.9146\n",
      "Epoch 31/120\n",
      " - 2s - loss: 1.0290 - val_loss: 0.9561\n",
      "Epoch 32/120\n",
      " - 2s - loss: 0.9825 - val_loss: 0.8937\n",
      "Epoch 33/120\n",
      " - 2s - loss: 0.9643 - val_loss: 0.8841\n",
      "Epoch 34/120\n",
      " - 2s - loss: 0.9706 - val_loss: 0.8848\n",
      "Epoch 35/120\n",
      " - 2s - loss: 0.9456 - val_loss: 0.8732\n",
      "Epoch 36/120\n",
      " - 2s - loss: 0.9562 - val_loss: 0.8615\n",
      "Epoch 37/120\n",
      " - 2s - loss: 0.9379 - val_loss: 0.8511\n",
      "Epoch 38/120\n",
      " - 2s - loss: 0.9151 - val_loss: 0.8579\n",
      "Epoch 39/120\n",
      " - 2s - loss: 0.9202 - val_loss: 0.8239\n",
      "Epoch 40/120\n",
      " - 2s - loss: 0.9066 - val_loss: 0.8196\n",
      "Epoch 41/120\n",
      " - 2s - loss: 0.8894 - val_loss: 0.8230\n",
      "Epoch 42/120\n",
      " - 2s - loss: 0.9290 - val_loss: 0.8141\n",
      "Epoch 43/120\n",
      " - 2s - loss: 0.8750 - val_loss: 0.7917\n",
      "Epoch 44/120\n",
      " - 2s - loss: 0.9022 - val_loss: 0.8617\n",
      "Epoch 45/120\n",
      " - 2s - loss: 0.8953 - val_loss: 0.8238\n",
      "Epoch 46/120\n",
      " - 2s - loss: 0.8600 - val_loss: 0.8245\n",
      "Epoch 47/120\n",
      " - 2s - loss: 0.8255 - val_loss: 0.7944\n",
      "Epoch 48/120\n",
      " - 2s - loss: 0.8274 - val_loss: 0.7222\n",
      "Epoch 49/120\n",
      " - 2s - loss: 0.7938 - val_loss: 0.7501\n",
      "Epoch 50/120\n",
      " - 2s - loss: 0.8326 - val_loss: 0.8258\n",
      "Epoch 51/120\n",
      " - 2s - loss: 0.8603 - val_loss: 0.8331\n",
      "Epoch 52/120\n",
      " - 2s - loss: 0.8286 - val_loss: 0.8129\n",
      "Epoch 53/120\n",
      " - 2s - loss: 0.8204 - val_loss: 0.7729\n",
      "Epoch 54/120\n",
      " - 2s - loss: 0.7905 - val_loss: 0.7421\n",
      "Epoch 55/120\n",
      " - 2s - loss: 0.7995 - val_loss: 0.6995\n",
      "Epoch 56/120\n",
      " - 2s - loss: 0.8574 - val_loss: 0.7982\n",
      "Epoch 57/120\n",
      " - 2s - loss: 0.8475 - val_loss: 0.8265\n",
      "Epoch 58/120\n",
      " - 2s - loss: 0.7777 - val_loss: 0.7797\n",
      "Epoch 59/120\n",
      " - 2s - loss: 0.7966 - val_loss: 0.7391\n",
      "Epoch 60/120\n",
      " - 2s - loss: 0.7894 - val_loss: 0.7496\n",
      "Epoch 61/120\n",
      " - 2s - loss: 0.8158 - val_loss: 0.7760\n",
      "Epoch 62/120\n",
      " - 2s - loss: 0.7599 - val_loss: 0.7744\n",
      "Epoch 63/120\n",
      " - 2s - loss: 0.7686 - val_loss: 0.7260\n",
      "Epoch 64/120\n",
      " - 2s - loss: 0.7369 - val_loss: 0.7163\n",
      "Epoch 65/120\n",
      " - 2s - loss: 0.7694 - val_loss: 0.7582\n",
      "Epoch 66/120\n",
      " - 2s - loss: 0.7401 - val_loss: 0.7961\n",
      "Epoch 67/120\n",
      " - 2s - loss: 0.7381 - val_loss: 0.7070\n",
      "Epoch 68/120\n",
      " - 2s - loss: 0.7101 - val_loss: 0.7004\n",
      "Epoch 69/120\n",
      " - 2s - loss: 0.7136 - val_loss: 0.7371\n",
      "Epoch 70/120\n",
      " - 2s - loss: 0.7225 - val_loss: 0.7069\n",
      "Epoch 71/120\n",
      " - 2s - loss: 0.6755 - val_loss: 0.6735\n",
      "Epoch 72/120\n",
      " - 2s - loss: 0.7631 - val_loss: 0.7026\n",
      "Epoch 73/120\n",
      " - 2s - loss: 0.6925 - val_loss: 0.7157\n",
      "Epoch 74/120\n",
      " - 2s - loss: 0.6862 - val_loss: 0.6423\n",
      "Epoch 75/120\n",
      " - 2s - loss: 0.7007 - val_loss: 0.7004\n",
      "Epoch 76/120\n",
      " - 2s - loss: 0.7515 - val_loss: 0.6618\n",
      "Epoch 77/120\n",
      " - 2s - loss: 0.6914 - val_loss: 0.6310\n",
      "Epoch 78/120\n",
      " - 2s - loss: 0.6733 - val_loss: 0.6330\n",
      "Epoch 79/120\n",
      " - 2s - loss: 0.6737 - val_loss: 0.6452\n",
      "Epoch 80/120\n",
      " - 2s - loss: 0.6686 - val_loss: 0.6410\n",
      "Epoch 81/120\n",
      " - 2s - loss: 0.6709 - val_loss: 0.6561\n",
      "Epoch 82/120\n",
      " - 2s - loss: 0.6838 - val_loss: 0.7301\n",
      "Epoch 83/120\n",
      " - 2s - loss: 0.6691 - val_loss: 0.6100\n",
      "Epoch 84/120\n",
      " - 2s - loss: 0.6571 - val_loss: 0.6846\n",
      "Epoch 85/120\n",
      " - 2s - loss: 0.6681 - val_loss: 0.6862\n",
      "Epoch 86/120\n",
      " - 2s - loss: 0.6545 - val_loss: 0.6873\n",
      "Epoch 87/120\n",
      " - 2s - loss: 0.6297 - val_loss: 0.5948\n",
      "Epoch 88/120\n",
      " - 2s - loss: 0.5961 - val_loss: 0.5979\n",
      "Epoch 89/120\n",
      " - 2s - loss: 0.6016 - val_loss: 0.5864\n",
      "Epoch 90/120\n",
      " - 2s - loss: 0.6055 - val_loss: 0.6032\n",
      "Epoch 91/120\n",
      " - 2s - loss: 0.6163 - val_loss: 0.6156\n",
      "Epoch 92/120\n",
      " - 2s - loss: 0.5952 - val_loss: 0.6061\n",
      "Epoch 93/120\n",
      " - 2s - loss: 0.6271 - val_loss: 0.6273\n",
      "Epoch 94/120\n",
      " - 2s - loss: 0.5790 - val_loss: 0.5816\n",
      "Epoch 95/120\n",
      " - 2s - loss: 0.6312 - val_loss: 0.5870\n",
      "Epoch 96/120\n",
      " - 2s - loss: 0.6179 - val_loss: 0.5589\n",
      "Epoch 97/120\n",
      " - 2s - loss: 0.5807 - val_loss: 0.5468\n",
      "Epoch 98/120\n",
      " - 2s - loss: 0.5474 - val_loss: 0.6374\n",
      "Epoch 99/120\n",
      " - 2s - loss: 0.5746 - val_loss: 0.5854\n",
      "Epoch 100/120\n",
      " - 2s - loss: 0.5678 - val_loss: 0.6637\n",
      "Epoch 101/120\n",
      " - 2s - loss: 0.5880 - val_loss: 0.5412\n",
      "Epoch 102/120\n",
      " - 2s - loss: 0.5589 - val_loss: 0.5665\n",
      "Epoch 103/120\n",
      " - 2s - loss: 0.6204 - val_loss: 0.6504\n",
      "Epoch 104/120\n",
      " - 2s - loss: 0.5769 - val_loss: 0.6182\n",
      "Epoch 105/120\n",
      " - 2s - loss: 0.5639 - val_loss: 0.5956\n",
      "Epoch 106/120\n",
      " - 2s - loss: 0.5568 - val_loss: 0.6036\n",
      "Epoch 107/120\n",
      " - 2s - loss: 0.5602 - val_loss: 0.5631\n",
      "Epoch 108/120\n",
      " - 2s - loss: 0.5966 - val_loss: 0.6432\n",
      "Epoch 109/120\n",
      " - 2s - loss: 0.5327 - val_loss: 0.5702\n",
      "Epoch 110/120\n",
      " - 2s - loss: 0.5386 - val_loss: 0.5680\n",
      "Epoch 111/120\n",
      " - 2s - loss: 0.5482 - val_loss: 0.7524\n",
      "Epoch 112/120\n",
      " - 2s - loss: 0.6022 - val_loss: 0.5997\n",
      "Epoch 113/120\n",
      " - 2s - loss: 0.5365 - val_loss: 0.6106\n",
      "Epoch 114/120\n",
      " - 2s - loss: 0.5732 - val_loss: 0.6614\n",
      "Epoch 115/120\n",
      " - 2s - loss: 0.5302 - val_loss: 0.5819\n",
      "Epoch 116/120\n",
      " - 2s - loss: 0.5160 - val_loss: 0.5710\n",
      "Epoch 117/120\n",
      " - 2s - loss: 0.4972 - val_loss: 0.5539\n",
      "Epoch 118/120\n",
      " - 2s - loss: 0.5079 - val_loss: 0.5659\n",
      "Epoch 119/120\n",
      " - 2s - loss: 0.5101 - val_loss: 0.5530\n",
      "Epoch 120/120\n",
      " - 2s - loss: 0.5097 - val_loss: 0.5715\n",
      "Train on 3045 samples, validate on 765 samples\n",
      "Epoch 1/120\n",
      " - 3s - loss: 1.9487 - val_loss: 1.7186\n",
      "Epoch 2/120\n",
      " - 2s - loss: 1.7076 - val_loss: 1.5969\n",
      "Epoch 3/120\n",
      " - 2s - loss: 1.6066 - val_loss: 1.5724\n",
      "Epoch 4/120\n",
      " - 2s - loss: 1.5645 - val_loss: 1.4999\n",
      "Epoch 5/120\n",
      " - 2s - loss: 1.4798 - val_loss: 1.4632\n",
      "Epoch 6/120\n",
      " - 2s - loss: 1.4321 - val_loss: 1.5087\n",
      "Epoch 7/120\n",
      " - 2s - loss: 1.4812 - val_loss: 1.4196\n",
      "Epoch 8/120\n",
      " - 2s - loss: 1.3993 - val_loss: 1.3949\n",
      "Epoch 9/120\n",
      " - 2s - loss: 1.3693 - val_loss: 1.2983\n",
      "Epoch 10/120\n",
      " - 2s - loss: 1.3531 - val_loss: 1.2913\n",
      "Epoch 11/120\n",
      " - 2s - loss: 1.3484 - val_loss: 1.3339\n",
      "Epoch 12/120\n",
      " - 2s - loss: 1.3074 - val_loss: 1.2641\n",
      "Epoch 13/120\n",
      " - 2s - loss: 1.2911 - val_loss: 1.2739\n",
      "Epoch 14/120\n",
      " - 2s - loss: 1.2651 - val_loss: 1.2509\n",
      "Epoch 15/120\n",
      " - 2s - loss: 1.2423 - val_loss: 1.1631\n",
      "Epoch 16/120\n",
      " - 2s - loss: 1.2014 - val_loss: 1.1655\n",
      "Epoch 17/120\n",
      " - 2s - loss: 1.2051 - val_loss: 1.2605\n",
      "Epoch 18/120\n",
      " - 2s - loss: 1.2081 - val_loss: 1.1890\n",
      "Epoch 19/120\n",
      " - 2s - loss: 1.1700 - val_loss: 1.1312\n",
      "Epoch 20/120\n",
      " - 2s - loss: 1.1510 - val_loss: 1.1401\n",
      "Epoch 21/120\n",
      " - 2s - loss: 1.1325 - val_loss: 1.1091\n",
      "Epoch 22/120\n",
      " - 2s - loss: 1.1486 - val_loss: 1.1353\n",
      "Epoch 23/120\n",
      " - 2s - loss: 1.0589 - val_loss: 1.0483\n",
      "Epoch 24/120\n",
      " - 2s - loss: 1.0851 - val_loss: 1.0779\n",
      "Epoch 25/120\n",
      " - 2s - loss: 1.0589 - val_loss: 1.0270\n",
      "Epoch 26/120\n",
      " - 2s - loss: 1.0277 - val_loss: 0.9874\n",
      "Epoch 27/120\n",
      " - 2s - loss: 1.0547 - val_loss: 1.0669\n",
      "Epoch 28/120\n",
      " - 2s - loss: 1.0634 - val_loss: 1.0283\n",
      "Epoch 29/120\n",
      " - 2s - loss: 1.0144 - val_loss: 1.0131\n",
      "Epoch 30/120\n",
      " - 2s - loss: 1.0050 - val_loss: 0.9787\n",
      "Epoch 31/120\n",
      " - 2s - loss: 1.0098 - val_loss: 1.0007\n",
      "Epoch 32/120\n",
      " - 2s - loss: 0.9903 - val_loss: 1.0225\n",
      "Epoch 33/120\n",
      " - 2s - loss: 1.0133 - val_loss: 0.9907\n",
      "Epoch 34/120\n",
      " - 2s - loss: 0.9757 - val_loss: 0.9902\n",
      "Epoch 35/120\n",
      " - 2s - loss: 0.9631 - val_loss: 0.9672\n",
      "Epoch 36/120\n",
      " - 2s - loss: 0.9787 - val_loss: 0.9816\n",
      "Epoch 37/120\n",
      " - 2s - loss: 0.9462 - val_loss: 0.9567\n",
      "Epoch 38/120\n",
      " - 2s - loss: 0.9174 - val_loss: 0.9043\n",
      "Epoch 39/120\n",
      " - 2s - loss: 0.9437 - val_loss: 0.9049\n",
      "Epoch 40/120\n",
      " - 2s - loss: 0.8764 - val_loss: 0.8817\n",
      "Epoch 41/120\n",
      " - 2s - loss: 0.8675 - val_loss: 0.8543\n",
      "Epoch 42/120\n",
      " - 2s - loss: 0.8667 - val_loss: 0.9554\n",
      "Epoch 43/120\n",
      " - 2s - loss: 0.8753 - val_loss: 0.9369\n",
      "Epoch 44/120\n",
      " - 2s - loss: 0.8461 - val_loss: 0.8298\n",
      "Epoch 45/120\n",
      " - 2s - loss: 0.8398 - val_loss: 0.8169\n",
      "Epoch 46/120\n",
      " - 2s - loss: 0.8214 - val_loss: 0.8641\n",
      "Epoch 47/120\n",
      " - 2s - loss: 0.8521 - val_loss: 0.8744\n",
      "Epoch 48/120\n",
      " - 2s - loss: 0.8549 - val_loss: 0.8388\n",
      "Epoch 49/120\n",
      " - 2s - loss: 0.7932 - val_loss: 0.7903\n",
      "Epoch 50/120\n",
      " - 2s - loss: 0.7682 - val_loss: 0.8221\n",
      "Epoch 51/120\n",
      " - 2s - loss: 0.7864 - val_loss: 0.8162\n",
      "Epoch 52/120\n",
      " - 2s - loss: 0.7544 - val_loss: 0.7501\n",
      "Epoch 53/120\n",
      " - 2s - loss: 0.7423 - val_loss: 0.7506\n",
      "Epoch 54/120\n",
      " - 2s - loss: 0.7402 - val_loss: 0.8403\n",
      "Epoch 55/120\n",
      " - 2s - loss: 0.7838 - val_loss: 0.7996\n",
      "Epoch 56/120\n",
      " - 2s - loss: 0.7365 - val_loss: 0.7653\n",
      "Epoch 57/120\n",
      " - 2s - loss: 0.6926 - val_loss: 0.7570\n",
      "Epoch 58/120\n",
      " - 2s - loss: 0.7059 - val_loss: 0.7962\n",
      "Epoch 59/120\n",
      " - 2s - loss: 0.7082 - val_loss: 0.6848\n",
      "Epoch 60/120\n",
      " - 2s - loss: 0.7153 - val_loss: 0.7841\n",
      "Epoch 61/120\n",
      " - 2s - loss: 0.7134 - val_loss: 0.7898\n",
      "Epoch 62/120\n",
      " - 2s - loss: 0.7277 - val_loss: 0.6618\n",
      "Epoch 63/120\n",
      " - 2s - loss: 0.6789 - val_loss: 0.7686\n",
      "Epoch 64/120\n",
      " - 2s - loss: 0.7087 - val_loss: 0.7521\n",
      "Epoch 65/120\n",
      " - 2s - loss: 0.6592 - val_loss: 0.7281\n",
      "Epoch 66/120\n",
      " - 2s - loss: 0.6821 - val_loss: 0.7020\n",
      "Epoch 67/120\n",
      " - 2s - loss: 0.6537 - val_loss: 0.7055\n",
      "Epoch 68/120\n",
      " - 2s - loss: 0.6407 - val_loss: 0.6690\n",
      "Epoch 69/120\n",
      " - 2s - loss: 0.6463 - val_loss: 0.6466\n",
      "Epoch 70/120\n",
      " - 2s - loss: 0.6133 - val_loss: 0.6561\n",
      "Epoch 71/120\n",
      " - 2s - loss: 0.5705 - val_loss: 0.6435\n",
      "Epoch 72/120\n",
      " - 2s - loss: 0.5944 - val_loss: 0.6265\n",
      "Epoch 73/120\n",
      " - 2s - loss: 0.6097 - val_loss: 0.6263\n",
      "Epoch 74/120\n",
      " - 2s - loss: 0.5739 - val_loss: 0.6141\n",
      "Epoch 75/120\n",
      " - 2s - loss: 0.5804 - val_loss: 0.6181\n",
      "Epoch 76/120\n",
      " - 2s - loss: 0.5592 - val_loss: 0.6134\n",
      "Epoch 77/120\n",
      " - 2s - loss: 0.5622 - val_loss: 0.6657\n",
      "Epoch 78/120\n",
      " - 2s - loss: 0.5572 - val_loss: 0.6202\n",
      "Epoch 79/120\n",
      " - 2s - loss: 0.6091 - val_loss: 0.6765\n",
      "Epoch 80/120\n",
      " - 2s - loss: 0.5843 - val_loss: 0.6887\n",
      "Epoch 81/120\n",
      " - 2s - loss: 0.5955 - val_loss: 0.6312\n",
      "Epoch 82/120\n",
      " - 2s - loss: 0.5563 - val_loss: 0.7223\n",
      "Epoch 83/120\n",
      " - 2s - loss: 0.5766 - val_loss: 0.6527\n",
      "Epoch 84/120\n",
      " - 2s - loss: 0.5439 - val_loss: 0.6367\n",
      "Epoch 85/120\n",
      " - 2s - loss: 0.5011 - val_loss: 0.6255\n",
      "Epoch 86/120\n",
      " - 2s - loss: 0.5396 - val_loss: 0.6068\n",
      "Epoch 87/120\n",
      " - 2s - loss: 0.5428 - val_loss: 0.6050\n",
      "Epoch 88/120\n",
      " - 2s - loss: 0.5058 - val_loss: 0.6108\n",
      "Epoch 89/120\n",
      " - 2s - loss: 0.5285 - val_loss: 0.6650\n",
      "Epoch 90/120\n",
      " - 2s - loss: 0.5202 - val_loss: 0.6168\n",
      "Epoch 91/120\n",
      " - 2s - loss: 0.4960 - val_loss: 0.5629\n",
      "Epoch 92/120\n",
      " - 2s - loss: 0.4871 - val_loss: 0.5968\n",
      "Epoch 93/120\n",
      " - 2s - loss: 0.4664 - val_loss: 0.5426\n",
      "Epoch 94/120\n",
      " - 2s - loss: 0.4922 - val_loss: 0.5804\n",
      "Epoch 95/120\n",
      " - 2s - loss: 0.4923 - val_loss: 0.5514\n",
      "Epoch 96/120\n",
      " - 2s - loss: 0.4881 - val_loss: 0.5610\n",
      "Epoch 97/120\n",
      " - 2s - loss: 0.4842 - val_loss: 0.5839\n",
      "Epoch 98/120\n",
      " - 2s - loss: 0.4572 - val_loss: 0.5501\n",
      "Epoch 99/120\n",
      " - 2s - loss: 0.4902 - val_loss: 0.6187\n",
      "Epoch 100/120\n",
      " - 2s - loss: 0.4593 - val_loss: 0.5863\n",
      "Epoch 101/120\n",
      " - 2s - loss: 0.4629 - val_loss: 0.5979\n",
      "Epoch 102/120\n",
      " - 2s - loss: 0.4507 - val_loss: 0.5880\n",
      "Epoch 103/120\n",
      " - 2s - loss: 0.4167 - val_loss: 0.5940\n",
      "Epoch 104/120\n",
      " - 2s - loss: 0.4406 - val_loss: 0.5856\n",
      "Epoch 105/120\n",
      " - 2s - loss: 0.4588 - val_loss: 0.5997\n",
      "Epoch 106/120\n",
      " - 2s - loss: 0.4545 - val_loss: 0.5752\n",
      "Epoch 107/120\n",
      " - 2s - loss: 0.4092 - val_loss: 0.5145\n",
      "Epoch 108/120\n",
      " - 2s - loss: 0.4509 - val_loss: 0.5712\n",
      "Epoch 109/120\n",
      " - 2s - loss: 0.4461 - val_loss: 0.6039\n",
      "Epoch 110/120\n",
      " - 2s - loss: 0.5499 - val_loss: 0.7629\n",
      "Epoch 111/120\n",
      " - 2s - loss: 0.5404 - val_loss: 0.6923\n",
      "Epoch 112/120\n",
      " - 2s - loss: 0.4935 - val_loss: 0.6153\n",
      "Epoch 113/120\n",
      " - 2s - loss: 0.4184 - val_loss: 0.5460\n",
      "Epoch 114/120\n",
      " - 2s - loss: 0.4321 - val_loss: 0.5310\n",
      "Epoch 115/120\n",
      " - 2s - loss: 0.4241 - val_loss: 0.5592\n",
      "Epoch 116/120\n",
      " - 2s - loss: 0.4225 - val_loss: 0.7138\n",
      "Epoch 117/120\n",
      " - 2s - loss: 0.5413 - val_loss: 0.7175\n",
      "Epoch 118/120\n",
      " - 2s - loss: 0.4800 - val_loss: 0.5915\n",
      "Epoch 119/120\n",
      " - 2s - loss: 0.4567 - val_loss: 0.6057\n",
      "Epoch 120/120\n",
      " - 2s - loss: 0.4337 - val_loss: 0.6002\n",
      "Train on 3048 samples, validate on 762 samples\n",
      "Epoch 1/120\n",
      " - 3s - loss: 1.9724 - val_loss: 1.7030\n",
      "Epoch 2/120\n",
      " - 2s - loss: 1.7014 - val_loss: 1.5104\n",
      "Epoch 3/120\n",
      " - 2s - loss: 1.6146 - val_loss: 1.5000\n",
      "Epoch 4/120\n",
      " - 2s - loss: 1.5593 - val_loss: 1.4791\n",
      "Epoch 5/120\n",
      " - 2s - loss: 1.5036 - val_loss: 1.4120\n",
      "Epoch 6/120\n",
      " - 2s - loss: 1.4514 - val_loss: 1.3318\n",
      "Epoch 7/120\n",
      " - 2s - loss: 1.3933 - val_loss: 1.2583\n",
      "Epoch 8/120\n",
      " - 2s - loss: 1.3182 - val_loss: 1.1944\n",
      "Epoch 9/120\n",
      " - 2s - loss: 1.2928 - val_loss: 1.1346\n",
      "Epoch 10/120\n",
      " - 2s - loss: 1.2667 - val_loss: 1.1233\n",
      "Epoch 11/120\n",
      " - 2s - loss: 1.2458 - val_loss: 1.0963\n",
      "Epoch 12/120\n",
      " - 2s - loss: 1.2180 - val_loss: 1.0627\n",
      "Epoch 13/120\n",
      " - 2s - loss: 1.1677 - val_loss: 0.9748\n",
      "Epoch 14/120\n",
      " - 2s - loss: 1.1120 - val_loss: 0.9527\n",
      "Epoch 15/120\n",
      " - 2s - loss: 1.1380 - val_loss: 0.9858\n",
      "Epoch 16/120\n",
      " - 2s - loss: 1.1066 - val_loss: 0.9924\n",
      "Epoch 17/120\n",
      " - 2s - loss: 1.0683 - val_loss: 0.9137\n",
      "Epoch 18/120\n",
      " - 2s - loss: 1.0475 - val_loss: 0.8908\n",
      "Epoch 19/120\n",
      " - 2s - loss: 1.0305 - val_loss: 0.8759\n",
      "Epoch 20/120\n",
      " - 2s - loss: 1.0275 - val_loss: 0.8979\n",
      "Epoch 21/120\n",
      " - 2s - loss: 0.9994 - val_loss: 0.8593\n",
      "Epoch 22/120\n",
      " - 2s - loss: 0.9710 - val_loss: 0.8457\n",
      "Epoch 23/120\n",
      " - 2s - loss: 1.0098 - val_loss: 0.8216\n",
      "Epoch 24/120\n",
      " - 2s - loss: 1.0129 - val_loss: 0.8950\n",
      "Epoch 25/120\n",
      " - 2s - loss: 0.9751 - val_loss: 0.8015\n",
      "Epoch 26/120\n",
      " - 2s - loss: 0.9336 - val_loss: 0.8182\n",
      "Epoch 27/120\n",
      " - 2s - loss: 0.9270 - val_loss: 0.8147\n",
      "Epoch 28/120\n",
      " - 2s - loss: 0.8996 - val_loss: 0.7504\n",
      "Epoch 29/120\n",
      " - 2s - loss: 0.8897 - val_loss: 0.7877\n",
      "Epoch 30/120\n",
      " - 2s - loss: 0.8737 - val_loss: 0.8149\n",
      "Epoch 31/120\n",
      " - 2s - loss: 0.9161 - val_loss: 0.9128\n",
      "Epoch 32/120\n",
      " - 2s - loss: 0.9693 - val_loss: 0.7806\n",
      "Epoch 33/120\n",
      " - 2s - loss: 0.9328 - val_loss: 0.7535\n",
      "Epoch 34/120\n",
      " - 2s - loss: 0.8778 - val_loss: 0.7399\n",
      "Epoch 35/120\n",
      " - 2s - loss: 0.8887 - val_loss: 0.8229\n",
      "Epoch 36/120\n",
      " - 2s - loss: 0.8707 - val_loss: 0.7772\n",
      "Epoch 37/120\n",
      " - 2s - loss: 0.8514 - val_loss: 0.6924\n",
      "Epoch 38/120\n",
      " - 2s - loss: 0.8282 - val_loss: 0.7291\n",
      "Epoch 39/120\n",
      " - 2s - loss: 0.8397 - val_loss: 0.7604\n",
      "Epoch 40/120\n",
      " - 2s - loss: 0.8283 - val_loss: 0.7117\n",
      "Epoch 41/120\n",
      " - 2s - loss: 0.7921 - val_loss: 0.7203\n",
      "Epoch 42/120\n",
      " - 2s - loss: 0.8036 - val_loss: 0.7300\n",
      "Epoch 43/120\n",
      " - 2s - loss: 0.7810 - val_loss: 0.6988\n",
      "Epoch 44/120\n",
      " - 2s - loss: 0.7483 - val_loss: 0.7215\n",
      "Epoch 45/120\n",
      " - 2s - loss: 0.7451 - val_loss: 0.6691\n",
      "Epoch 46/120\n",
      " - 2s - loss: 0.7519 - val_loss: 0.6921\n",
      "Epoch 47/120\n",
      " - 2s - loss: 0.7029 - val_loss: 0.6831\n",
      "Epoch 48/120\n",
      " - 2s - loss: 0.7121 - val_loss: 0.6307\n",
      "Epoch 49/120\n",
      " - 2s - loss: 0.7172 - val_loss: 0.6145\n",
      "Epoch 50/120\n",
      " - 2s - loss: 0.7193 - val_loss: 0.6577\n",
      "Epoch 51/120\n",
      " - 2s - loss: 0.6940 - val_loss: 0.6452\n",
      "Epoch 52/120\n",
      " - 2s - loss: 0.6934 - val_loss: 0.6204\n",
      "Epoch 53/120\n",
      " - 2s - loss: 0.6680 - val_loss: 0.6084\n",
      "Epoch 54/120\n",
      " - 2s - loss: 0.6747 - val_loss: 0.6406\n",
      "Epoch 55/120\n",
      " - 2s - loss: 0.6785 - val_loss: 0.7213\n",
      "Epoch 56/120\n",
      " - 2s - loss: 0.7313 - val_loss: 0.6207\n",
      "Epoch 57/120\n",
      " - 2s - loss: 0.6569 - val_loss: 0.6093\n",
      "Epoch 58/120\n",
      " - 2s - loss: 0.6456 - val_loss: 0.6655\n",
      "Epoch 59/120\n",
      " - 2s - loss: 0.6678 - val_loss: 0.5920\n",
      "Epoch 60/120\n",
      " - 2s - loss: 0.6973 - val_loss: 0.6449\n",
      "Epoch 61/120\n",
      " - 2s - loss: 0.6798 - val_loss: 0.6187\n",
      "Epoch 62/120\n",
      " - 2s - loss: 0.6299 - val_loss: 0.6063\n",
      "Epoch 63/120\n",
      " - 2s - loss: 0.5985 - val_loss: 0.6194\n",
      "Epoch 64/120\n",
      " - 2s - loss: 0.5871 - val_loss: 0.6160\n",
      "Epoch 65/120\n",
      " - 2s - loss: 0.5943 - val_loss: 0.5758\n",
      "Epoch 66/120\n",
      " - 2s - loss: 0.6132 - val_loss: 0.5906\n",
      "Epoch 67/120\n",
      " - 2s - loss: 0.6084 - val_loss: 0.6201\n",
      "Epoch 68/120\n",
      " - 2s - loss: 0.5764 - val_loss: 0.5972\n",
      "Epoch 69/120\n",
      " - 2s - loss: 0.5659 - val_loss: 0.6013\n",
      "Epoch 70/120\n",
      " - 2s - loss: 0.6201 - val_loss: 0.6618\n",
      "Epoch 71/120\n",
      " - 2s - loss: 0.6168 - val_loss: 0.5735\n",
      "Epoch 72/120\n",
      " - 2s - loss: 0.5500 - val_loss: 0.5151\n",
      "Epoch 73/120\n",
      " - 2s - loss: 0.5417 - val_loss: 0.5642\n",
      "Epoch 74/120\n",
      " - 2s - loss: 0.5695 - val_loss: 0.5543\n",
      "Epoch 75/120\n",
      " - 2s - loss: 0.5714 - val_loss: 0.5225\n",
      "Epoch 76/120\n",
      " - 2s - loss: 0.5236 - val_loss: 0.5313\n",
      "Epoch 77/120\n",
      " - 2s - loss: 0.5215 - val_loss: 0.5482\n",
      "Epoch 78/120\n",
      " - 2s - loss: 0.5207 - val_loss: 0.5572\n",
      "Epoch 79/120\n",
      " - 2s - loss: 0.5522 - val_loss: 0.5535\n",
      "Epoch 80/120\n",
      " - 2s - loss: 0.5193 - val_loss: 0.4906\n",
      "Epoch 81/120\n",
      " - 2s - loss: 0.5084 - val_loss: 0.5897\n",
      "Epoch 82/120\n",
      " - 2s - loss: 0.5141 - val_loss: 0.5727\n",
      "Epoch 83/120\n",
      " - 2s - loss: 0.5059 - val_loss: 0.5131\n",
      "Epoch 84/120\n",
      " - 2s - loss: 0.4773 - val_loss: 0.5500\n",
      "Epoch 85/120\n",
      " - 2s - loss: 0.4949 - val_loss: 0.4829\n",
      "Epoch 86/120\n",
      " - 2s - loss: 0.4774 - val_loss: 0.4836\n",
      "Epoch 87/120\n",
      " - 2s - loss: 0.4823 - val_loss: 0.5062\n",
      "Epoch 88/120\n",
      " - 2s - loss: 0.4782 - val_loss: 0.4595\n",
      "Epoch 89/120\n",
      " - 2s - loss: 0.4940 - val_loss: 0.5682\n",
      "Epoch 90/120\n",
      " - 2s - loss: 0.4723 - val_loss: 0.4871\n",
      "Epoch 91/120\n",
      " - 2s - loss: 0.5137 - val_loss: 0.4941\n",
      "Epoch 92/120\n",
      " - 2s - loss: 0.4611 - val_loss: 0.4693\n",
      "Epoch 93/120\n",
      " - 2s - loss: 0.4566 - val_loss: 0.4981\n",
      "Epoch 94/120\n",
      " - 2s - loss: 0.4286 - val_loss: 0.5084\n",
      "Epoch 95/120\n",
      " - 2s - loss: 0.4354 - val_loss: 0.4896\n",
      "Epoch 96/120\n",
      " - 2s - loss: 0.4086 - val_loss: 0.4511\n",
      "Epoch 97/120\n",
      " - 2s - loss: 0.4148 - val_loss: 0.4478\n",
      "Epoch 98/120\n",
      " - 2s - loss: 0.4214 - val_loss: 0.4582\n",
      "Epoch 99/120\n",
      " - 2s - loss: 0.3978 - val_loss: 0.4719\n",
      "Epoch 100/120\n",
      " - 2s - loss: 0.3972 - val_loss: 0.4070\n",
      "Epoch 101/120\n",
      " - 2s - loss: 0.4098 - val_loss: 0.4565\n",
      "Epoch 102/120\n",
      " - 2s - loss: 0.3945 - val_loss: 0.4853\n",
      "Epoch 103/120\n",
      " - 2s - loss: 0.3930 - val_loss: 0.5047\n",
      "Epoch 104/120\n",
      " - 2s - loss: 0.3973 - val_loss: 0.4606\n",
      "Epoch 105/120\n",
      " - 2s - loss: 0.4267 - val_loss: 0.4648\n",
      "Epoch 106/120\n",
      " - 2s - loss: 0.4510 - val_loss: 0.4830\n",
      "Epoch 107/120\n",
      " - 2s - loss: 0.4105 - val_loss: 0.4716\n",
      "Epoch 108/120\n",
      " - 2s - loss: 0.4298 - val_loss: 0.4859\n",
      "Epoch 109/120\n",
      " - 2s - loss: 0.4082 - val_loss: 0.4570\n",
      "Epoch 110/120\n",
      " - 2s - loss: 0.4015 - val_loss: 0.5096\n",
      "Epoch 111/120\n",
      " - 2s - loss: 0.4209 - val_loss: 0.5745\n",
      "Epoch 112/120\n",
      " - 2s - loss: 0.3930 - val_loss: 0.5391\n",
      "Epoch 113/120\n",
      " - 2s - loss: 0.3959 - val_loss: 0.5195\n",
      "Epoch 114/120\n",
      " - 2s - loss: 0.4257 - val_loss: 0.4483\n",
      "Epoch 115/120\n",
      " - 2s - loss: 0.3847 - val_loss: 0.4472\n",
      "Epoch 116/120\n",
      " - 2s - loss: 0.3713 - val_loss: 0.4141\n",
      "Epoch 117/120\n",
      " - 2s - loss: 0.3313 - val_loss: 0.4611\n",
      "Epoch 118/120\n",
      " - 2s - loss: 0.3536 - val_loss: 0.4880\n",
      "Epoch 119/120\n",
      " - 2s - loss: 0.3859 - val_loss: 0.4925\n",
      "Epoch 120/120\n",
      " - 2s - loss: 0.3623 - val_loss: 0.4052\n",
      "Train on 3050 samples, validate on 760 samples\n",
      "Epoch 1/120\n",
      " - 4s - loss: 1.9017 - val_loss: 1.7051\n",
      "Epoch 2/120\n",
      " - 2s - loss: 1.6945 - val_loss: 1.6480\n",
      "Epoch 3/120\n",
      " - 2s - loss: 1.6052 - val_loss: 1.4959\n",
      "Epoch 4/120\n",
      " - 2s - loss: 1.5198 - val_loss: 1.4930\n",
      "Epoch 5/120\n",
      " - 2s - loss: 1.5022 - val_loss: 1.4207\n",
      "Epoch 6/120\n",
      " - 2s - loss: 1.4035 - val_loss: 1.3405\n",
      "Epoch 7/120\n",
      " - 2s - loss: 1.3251 - val_loss: 1.2265\n",
      "Epoch 8/120\n",
      " - 2s - loss: 1.4007 - val_loss: 1.3031\n",
      "Epoch 9/120\n",
      " - 2s - loss: 1.3319 - val_loss: 1.2289\n",
      "Epoch 10/120\n",
      " - 2s - loss: 1.2498 - val_loss: 1.2072\n",
      "Epoch 11/120\n",
      " - 2s - loss: 1.2349 - val_loss: 1.1996\n",
      "Epoch 12/120\n",
      " - 2s - loss: 1.2141 - val_loss: 1.1220\n",
      "Epoch 13/120\n",
      " - 2s - loss: 1.1727 - val_loss: 1.0877\n",
      "Epoch 14/120\n",
      " - 2s - loss: 1.2016 - val_loss: 1.1723\n",
      "Epoch 15/120\n",
      " - 2s - loss: 1.2457 - val_loss: 1.1492\n",
      "Epoch 16/120\n",
      " - 2s - loss: 1.2207 - val_loss: 1.1911\n",
      "Epoch 17/120\n",
      " - 2s - loss: 1.2198 - val_loss: 1.1381\n",
      "Epoch 18/120\n",
      " - 2s - loss: 1.1563 - val_loss: 1.0888\n",
      "Epoch 19/120\n",
      " - 2s - loss: 1.1495 - val_loss: 1.0591\n",
      "Epoch 20/120\n",
      " - 2s - loss: 1.0945 - val_loss: 1.0176\n",
      "Epoch 21/120\n",
      " - 2s - loss: 1.1041 - val_loss: 1.0510\n",
      "Epoch 22/120\n",
      " - 2s - loss: 1.0655 - val_loss: 1.0076\n",
      "Epoch 23/120\n",
      " - 2s - loss: 1.0844 - val_loss: 0.9707\n",
      "Epoch 24/120\n",
      " - 2s - loss: 1.0548 - val_loss: 1.0073\n",
      "Epoch 25/120\n",
      " - 2s - loss: 1.0494 - val_loss: 0.9940\n",
      "Epoch 26/120\n",
      " - 2s - loss: 1.0135 - val_loss: 0.9278\n",
      "Epoch 27/120\n",
      " - 2s - loss: 0.9926 - val_loss: 0.9252\n",
      "Epoch 28/120\n",
      " - 2s - loss: 0.9490 - val_loss: 0.8940\n",
      "Epoch 29/120\n",
      " - 2s - loss: 0.9438 - val_loss: 0.9616\n",
      "Epoch 30/120\n",
      " - 2s - loss: 0.9454 - val_loss: 0.8569\n",
      "Epoch 31/120\n",
      " - 2s - loss: 1.0317 - val_loss: 0.9361\n",
      "Epoch 32/120\n",
      " - 2s - loss: 0.9862 - val_loss: 0.9261\n",
      "Epoch 33/120\n",
      " - 2s - loss: 0.9768 - val_loss: 0.9479\n",
      "Epoch 34/120\n",
      " - 2s - loss: 0.9432 - val_loss: 0.9103\n",
      "Epoch 35/120\n",
      " - 2s - loss: 0.9036 - val_loss: 0.8606\n",
      "Epoch 36/120\n",
      " - 2s - loss: 0.9723 - val_loss: 0.9357\n",
      "Epoch 37/120\n",
      " - 2s - loss: 0.9587 - val_loss: 0.8849\n",
      "Epoch 38/120\n",
      " - 2s - loss: 0.9042 - val_loss: 0.8287\n",
      "Epoch 39/120\n",
      " - 2s - loss: 0.8986 - val_loss: 0.8742\n",
      "Epoch 40/120\n",
      " - 2s - loss: 0.8594 - val_loss: 0.8109\n",
      "Epoch 41/120\n",
      " - 2s - loss: 0.8541 - val_loss: 0.8636\n",
      "Epoch 42/120\n",
      " - 2s - loss: 0.8649 - val_loss: 0.8395\n",
      "Epoch 43/120\n",
      " - 2s - loss: 0.8370 - val_loss: 0.7897\n",
      "Epoch 44/120\n",
      " - 2s - loss: 0.8367 - val_loss: 0.8038\n",
      "Epoch 45/120\n",
      " - 2s - loss: 0.8174 - val_loss: 0.7987\n",
      "Epoch 46/120\n",
      " - 2s - loss: 0.8198 - val_loss: 0.7887\n",
      "Epoch 47/120\n",
      " - 2s - loss: 0.8149 - val_loss: 0.7732\n",
      "Epoch 48/120\n",
      " - 2s - loss: 0.7767 - val_loss: 0.7572\n",
      "Epoch 49/120\n",
      " - 2s - loss: 0.7775 - val_loss: 0.7227\n",
      "Epoch 50/120\n",
      " - 2s - loss: 0.7666 - val_loss: 0.8113\n",
      "Epoch 51/120\n",
      " - 2s - loss: 0.7726 - val_loss: 0.7357\n",
      "Epoch 52/120\n",
      " - 2s - loss: 0.7692 - val_loss: 0.7437\n",
      "Epoch 53/120\n",
      " - 2s - loss: 0.7209 - val_loss: 0.7563\n",
      "Epoch 54/120\n",
      " - 2s - loss: 0.7360 - val_loss: 0.7270\n",
      "Epoch 55/120\n",
      " - 2s - loss: 0.7418 - val_loss: 0.7450\n",
      "Epoch 56/120\n",
      " - 2s - loss: 0.7522 - val_loss: 0.7354\n",
      "Epoch 57/120\n",
      " - 2s - loss: 0.7196 - val_loss: 0.7048\n",
      "Epoch 58/120\n",
      " - 2s - loss: 0.7120 - val_loss: 0.7382\n",
      "Epoch 59/120\n",
      " - 2s - loss: 0.7110 - val_loss: 0.6776\n",
      "Epoch 60/120\n",
      " - 2s - loss: 0.7117 - val_loss: 0.7330\n",
      "Epoch 61/120\n",
      " - 2s - loss: 0.7247 - val_loss: 0.7042\n",
      "Epoch 62/120\n",
      " - 2s - loss: 0.7090 - val_loss: 0.7051\n",
      "Epoch 63/120\n",
      " - 2s - loss: 0.6698 - val_loss: 0.7406\n",
      "Epoch 64/120\n",
      " - 2s - loss: 0.6987 - val_loss: 0.7532\n",
      "Epoch 65/120\n",
      " - 2s - loss: 0.6947 - val_loss: 0.6983\n",
      "Epoch 66/120\n",
      " - 2s - loss: 0.6757 - val_loss: 0.6786\n",
      "Epoch 67/120\n",
      " - 2s - loss: 0.6682 - val_loss: 0.6735\n",
      "Epoch 68/120\n",
      " - 2s - loss: 0.6539 - val_loss: 0.6319\n",
      "Epoch 69/120\n",
      " - 2s - loss: 0.6445 - val_loss: 0.6445\n",
      "Epoch 70/120\n",
      " - 2s - loss: 0.6728 - val_loss: 0.6383\n",
      "Epoch 71/120\n",
      " - 2s - loss: 0.6322 - val_loss: 0.6783\n",
      "Epoch 72/120\n",
      " - 2s - loss: 0.6483 - val_loss: 0.7718\n",
      "Epoch 73/120\n",
      " - 2s - loss: 0.6635 - val_loss: 0.6570\n",
      "Epoch 74/120\n",
      " - 2s - loss: 0.6172 - val_loss: 0.6168\n",
      "Epoch 75/120\n",
      " - 2s - loss: 0.5950 - val_loss: 0.6603\n",
      "Epoch 76/120\n",
      " - 2s - loss: 0.6177 - val_loss: 0.6764\n",
      "Epoch 77/120\n",
      " - 2s - loss: 0.5868 - val_loss: 0.6206\n",
      "Epoch 78/120\n",
      " - 2s - loss: 0.6058 - val_loss: 0.6474\n",
      "Epoch 79/120\n",
      " - 2s - loss: 0.5862 - val_loss: 0.6252\n",
      "Epoch 80/120\n",
      " - 2s - loss: 0.5873 - val_loss: 0.6079\n",
      "Epoch 81/120\n",
      " - 2s - loss: 0.5907 - val_loss: 0.6120\n",
      "Epoch 82/120\n",
      " - 2s - loss: 0.5879 - val_loss: 0.6790\n",
      "Epoch 83/120\n",
      " - 2s - loss: 0.5816 - val_loss: 0.6921\n",
      "Epoch 84/120\n",
      " - 2s - loss: 0.5767 - val_loss: 0.6699\n",
      "Epoch 85/120\n",
      " - 2s - loss: 0.5478 - val_loss: 0.5807\n",
      "Epoch 86/120\n",
      " - 2s - loss: 0.5451 - val_loss: 0.6149\n",
      "Epoch 87/120\n",
      " - 2s - loss: 0.5603 - val_loss: 0.6171\n",
      "Epoch 88/120\n",
      " - 2s - loss: 0.5550 - val_loss: 0.5694\n",
      "Epoch 89/120\n",
      " - 2s - loss: 0.5497 - val_loss: 0.6244\n",
      "Epoch 90/120\n",
      " - 2s - loss: 0.5516 - val_loss: 0.5355\n",
      "Epoch 91/120\n",
      " - 2s - loss: 0.5182 - val_loss: 0.5445\n",
      "Epoch 92/120\n",
      " - 2s - loss: 0.4949 - val_loss: 0.6113\n",
      "Epoch 93/120\n",
      " - 2s - loss: 0.5095 - val_loss: 0.5561\n",
      "Epoch 94/120\n",
      " - 2s - loss: 0.5118 - val_loss: 0.6217\n",
      "Epoch 95/120\n",
      " - 2s - loss: 0.4919 - val_loss: 0.6221\n",
      "Epoch 96/120\n",
      " - 2s - loss: 0.4852 - val_loss: 0.5506\n",
      "Epoch 97/120\n",
      " - 2s - loss: 0.5276 - val_loss: 0.5834\n",
      "Epoch 98/120\n",
      " - 2s - loss: 0.4844 - val_loss: 0.6015\n",
      "Epoch 99/120\n",
      " - 2s - loss: 0.4978 - val_loss: 0.5867\n",
      "Epoch 100/120\n",
      " - 2s - loss: 0.4924 - val_loss: 0.5807\n",
      "Epoch 101/120\n",
      " - 2s - loss: 0.4642 - val_loss: 0.5518\n",
      "Epoch 102/120\n",
      " - 2s - loss: 0.4858 - val_loss: 0.6309\n",
      "Epoch 103/120\n",
      " - 2s - loss: 0.4824 - val_loss: 0.5366\n",
      "Epoch 104/120\n",
      " - 2s - loss: 0.4775 - val_loss: 0.6469\n",
      "Epoch 105/120\n",
      " - 2s - loss: 0.4767 - val_loss: 0.5298\n",
      "Epoch 106/120\n",
      " - 2s - loss: 0.4863 - val_loss: 0.6025\n",
      "Epoch 107/120\n",
      " - 2s - loss: 0.4503 - val_loss: 0.5012\n",
      "Epoch 108/120\n",
      " - 2s - loss: 0.4479 - val_loss: 0.5308\n",
      "Epoch 109/120\n",
      " - 2s - loss: 0.4611 - val_loss: 0.5916\n",
      "Epoch 110/120\n",
      " - 2s - loss: 0.4424 - val_loss: 0.4967\n",
      "Epoch 111/120\n",
      " - 2s - loss: 0.4549 - val_loss: 0.5651\n",
      "Epoch 112/120\n",
      " - 2s - loss: 0.4853 - val_loss: 0.6375\n",
      "Epoch 113/120\n",
      " - 2s - loss: 0.5080 - val_loss: 0.5377\n",
      "Epoch 114/120\n",
      " - 2s - loss: 0.4553 - val_loss: 0.5336\n",
      "Epoch 115/120\n",
      " - 2s - loss: 0.4408 - val_loss: 0.5363\n",
      "Epoch 116/120\n",
      " - 2s - loss: 0.4584 - val_loss: 0.5659\n",
      "Epoch 117/120\n",
      " - 2s - loss: 0.4375 - val_loss: 0.5068\n",
      "Epoch 118/120\n",
      " - 2s - loss: 0.4242 - val_loss: 0.5016\n",
      "Epoch 119/120\n",
      " - 2s - loss: 0.4050 - val_loss: 0.4935\n",
      "Epoch 120/120\n",
      " - 2s - loss: 0.4184 - val_loss: 0.5551\n",
      "Train on 3053 samples, validate on 757 samples\n",
      "Epoch 1/120\n",
      " - 4s - loss: 1.9903 - val_loss: 1.7902\n",
      "Epoch 2/120\n",
      " - 2s - loss: 1.7159 - val_loss: 1.5486\n",
      "Epoch 3/120\n",
      " - 2s - loss: 1.5957 - val_loss: 1.5360\n",
      "Epoch 4/120\n",
      " - 2s - loss: 1.5274 - val_loss: 1.4106\n",
      "Epoch 5/120\n",
      " - 2s - loss: 1.4482 - val_loss: 1.3519\n",
      "Epoch 6/120\n",
      " - 2s - loss: 1.4051 - val_loss: 1.3774\n",
      "Epoch 7/120\n",
      " - 2s - loss: 1.3519 - val_loss: 1.2904\n",
      "Epoch 8/120\n",
      " - 2s - loss: 1.3015 - val_loss: 1.2358\n",
      "Epoch 9/120\n",
      " - 2s - loss: 1.2709 - val_loss: 1.2253\n",
      "Epoch 10/120\n",
      " - 2s - loss: 1.2568 - val_loss: 1.2095\n",
      "Epoch 11/120\n",
      " - 2s - loss: 1.2114 - val_loss: 1.0948\n",
      "Epoch 12/120\n",
      " - 2s - loss: 1.1365 - val_loss: 1.0696\n",
      "Epoch 13/120\n",
      " - 2s - loss: 1.1559 - val_loss: 1.0624\n",
      "Epoch 14/120\n",
      " - 2s - loss: 1.1043 - val_loss: 1.0149\n",
      "Epoch 15/120\n",
      " - 2s - loss: 1.0934 - val_loss: 1.0240\n",
      "Epoch 16/120\n",
      " - 2s - loss: 1.1067 - val_loss: 1.0204\n",
      "Epoch 17/120\n",
      " - 2s - loss: 1.0768 - val_loss: 0.9428\n",
      "Epoch 18/120\n",
      " - 2s - loss: 1.0458 - val_loss: 0.9747\n",
      "Epoch 19/120\n",
      " - 2s - loss: 1.0368 - val_loss: 1.1337\n",
      "Epoch 20/120\n",
      " - 2s - loss: 1.0730 - val_loss: 0.9669\n",
      "Epoch 21/120\n",
      " - 2s - loss: 1.0086 - val_loss: 0.9599\n",
      "Epoch 22/120\n",
      " - 2s - loss: 1.0018 - val_loss: 0.9814\n",
      "Epoch 23/120\n",
      " - 2s - loss: 0.9805 - val_loss: 0.9483\n",
      "Epoch 24/120\n",
      " - 2s - loss: 0.9724 - val_loss: 0.9159\n",
      "Epoch 25/120\n",
      " - 2s - loss: 0.9454 - val_loss: 0.8731\n",
      "Epoch 26/120\n",
      " - 2s - loss: 0.9797 - val_loss: 0.8908\n",
      "Epoch 27/120\n",
      " - 2s - loss: 0.9639 - val_loss: 0.9431\n",
      "Epoch 28/120\n",
      " - 2s - loss: 0.9650 - val_loss: 0.9722\n",
      "Epoch 29/120\n",
      " - 2s - loss: 0.9432 - val_loss: 0.8550\n",
      "Epoch 30/120\n",
      " - 2s - loss: 0.9305 - val_loss: 0.9165\n",
      "Epoch 31/120\n",
      " - 2s - loss: 0.8874 - val_loss: 0.9394\n",
      "Epoch 32/120\n",
      " - 2s - loss: 0.8944 - val_loss: 0.9402\n",
      "Epoch 33/120\n",
      " - 2s - loss: 0.8808 - val_loss: 0.8307\n",
      "Epoch 34/120\n",
      " - 2s - loss: 0.9004 - val_loss: 0.8476\n",
      "Epoch 35/120\n",
      " - 2s - loss: 0.8631 - val_loss: 0.8719\n",
      "Epoch 36/120\n",
      " - 2s - loss: 0.8604 - val_loss: 0.8156\n",
      "Epoch 37/120\n",
      " - 2s - loss: 0.8750 - val_loss: 0.8493\n",
      "Epoch 38/120\n",
      " - 2s - loss: 0.8467 - val_loss: 0.8547\n",
      "Epoch 39/120\n",
      " - 2s - loss: 0.8118 - val_loss: 0.7814\n",
      "Epoch 40/120\n",
      " - 2s - loss: 0.7895 - val_loss: 0.8202\n",
      "Epoch 41/120\n",
      " - 2s - loss: 0.8004 - val_loss: 0.9081\n",
      "Epoch 42/120\n",
      " - 2s - loss: 0.7986 - val_loss: 0.8050\n",
      "Epoch 43/120\n",
      " - 2s - loss: 0.7851 - val_loss: 0.7953\n",
      "Epoch 44/120\n",
      " - 2s - loss: 0.7923 - val_loss: 0.7958\n",
      "Epoch 45/120\n",
      " - 2s - loss: 0.7515 - val_loss: 0.7685\n",
      "Epoch 46/120\n",
      " - 2s - loss: 0.8294 - val_loss: 0.7763\n",
      "Epoch 47/120\n",
      " - 2s - loss: 0.7756 - val_loss: 0.9190\n",
      "Epoch 48/120\n",
      " - 2s - loss: 0.8315 - val_loss: 0.8012\n",
      "Epoch 49/120\n",
      " - 2s - loss: 0.7708 - val_loss: 0.7918\n",
      "Epoch 50/120\n",
      " - 2s - loss: 0.7707 - val_loss: 0.7617\n",
      "Epoch 51/120\n",
      " - 2s - loss: 0.7305 - val_loss: 0.8089\n",
      "Epoch 52/120\n",
      " - 2s - loss: 0.7349 - val_loss: 0.7533\n",
      "Epoch 53/120\n",
      " - 2s - loss: 0.7097 - val_loss: 0.7447\n",
      "Epoch 54/120\n",
      " - 2s - loss: 0.7572 - val_loss: 0.7580\n",
      "Epoch 55/120\n",
      " - 2s - loss: 0.7324 - val_loss: 0.7328\n",
      "Epoch 56/120\n",
      " - 2s - loss: 0.6918 - val_loss: 0.7229\n",
      "Epoch 57/120\n",
      " - 2s - loss: 0.6770 - val_loss: 0.7662\n",
      "Epoch 58/120\n",
      " - 2s - loss: 0.6504 - val_loss: 0.6842\n",
      "Epoch 59/120\n",
      " - 2s - loss: 0.6433 - val_loss: 0.7113\n",
      "Epoch 60/120\n",
      " - 2s - loss: 0.6335 - val_loss: 0.6805\n",
      "Epoch 61/120\n",
      " - 2s - loss: 0.6500 - val_loss: 0.6505\n",
      "Epoch 62/120\n",
      " - 2s - loss: 0.6069 - val_loss: 0.6623\n",
      "Epoch 63/120\n",
      " - 2s - loss: 0.6247 - val_loss: 0.6449\n",
      "Epoch 64/120\n",
      " - 2s - loss: 0.6359 - val_loss: 0.6759\n",
      "Epoch 65/120\n",
      " - 2s - loss: 0.6575 - val_loss: 0.6898\n",
      "Epoch 66/120\n",
      " - 2s - loss: 0.6591 - val_loss: 0.6798\n",
      "Epoch 67/120\n",
      " - 2s - loss: 0.6341 - val_loss: 0.6459\n",
      "Epoch 68/120\n",
      " - 2s - loss: 0.6032 - val_loss: 0.5813\n",
      "Epoch 69/120\n",
      " - 2s - loss: 0.6108 - val_loss: 0.6693\n",
      "Epoch 70/120\n",
      " - 2s - loss: 0.5789 - val_loss: 0.6087\n",
      "Epoch 71/120\n",
      " - 2s - loss: 0.6061 - val_loss: 0.6201\n",
      "Epoch 72/120\n",
      " - 2s - loss: 0.6151 - val_loss: 0.6166\n",
      "Epoch 73/120\n",
      " - 2s - loss: 0.5597 - val_loss: 0.6445\n",
      "Epoch 74/120\n",
      " - 2s - loss: 0.6041 - val_loss: 0.5974\n",
      "Epoch 75/120\n",
      " - 2s - loss: 0.5466 - val_loss: 0.5657\n",
      "Epoch 76/120\n",
      " - 2s - loss: 0.5763 - val_loss: 0.6311\n",
      "Epoch 77/120\n",
      " - 2s - loss: 0.5791 - val_loss: 0.6171\n",
      "Epoch 78/120\n",
      " - 2s - loss: 0.5454 - val_loss: 0.6085\n",
      "Epoch 79/120\n",
      " - 2s - loss: 0.5417 - val_loss: 0.5669\n",
      "Epoch 80/120\n",
      " - 2s - loss: 0.5272 - val_loss: 0.5927\n",
      "Epoch 81/120\n",
      " - 2s - loss: 0.5435 - val_loss: 0.6343\n",
      "Epoch 82/120\n",
      " - 2s - loss: 0.4858 - val_loss: 0.5396\n",
      "Epoch 83/120\n",
      " - 2s - loss: 0.5079 - val_loss: 0.6037\n",
      "Epoch 84/120\n",
      " - 2s - loss: 0.5008 - val_loss: 0.5671\n",
      "Epoch 85/120\n",
      " - 2s - loss: 0.5297 - val_loss: 0.5634\n",
      "Epoch 86/120\n",
      " - 2s - loss: 0.5044 - val_loss: 0.6445\n",
      "Epoch 87/120\n",
      " - 2s - loss: 0.4933 - val_loss: 0.5435\n",
      "Epoch 88/120\n",
      " - 2s - loss: 0.4592 - val_loss: 0.6089\n",
      "Epoch 89/120\n",
      " - 2s - loss: 0.4783 - val_loss: 0.5748\n",
      "Epoch 90/120\n",
      " - 2s - loss: 0.4925 - val_loss: 0.5629\n",
      "Epoch 91/120\n",
      " - 2s - loss: 0.4474 - val_loss: 0.5264\n",
      "Epoch 92/120\n",
      " - 2s - loss: 0.4543 - val_loss: 0.5569\n",
      "Epoch 93/120\n",
      " - 2s - loss: 0.4768 - val_loss: 0.5679\n",
      "Epoch 94/120\n",
      " - 2s - loss: 0.4538 - val_loss: 0.5915\n",
      "Epoch 95/120\n",
      " - 2s - loss: 0.4715 - val_loss: 0.5802\n",
      "Epoch 96/120\n",
      " - 2s - loss: 0.4415 - val_loss: 0.5876\n",
      "Epoch 97/120\n",
      " - 2s - loss: 0.4332 - val_loss: 0.5557\n",
      "Epoch 98/120\n",
      " - 2s - loss: 0.4639 - val_loss: 0.5700\n",
      "Epoch 99/120\n",
      " - 2s - loss: 0.4248 - val_loss: 0.5363\n",
      "Epoch 100/120\n",
      " - 2s - loss: 0.4101 - val_loss: 0.6006\n",
      "Epoch 101/120\n",
      " - 2s - loss: 0.4569 - val_loss: 0.5584\n",
      "Epoch 102/120\n",
      " - 2s - loss: 0.4399 - val_loss: 0.6046\n",
      "Epoch 103/120\n",
      " - 2s - loss: 0.4256 - val_loss: 0.5486\n",
      "Epoch 104/120\n",
      " - 2s - loss: 0.4699 - val_loss: 0.5505\n",
      "Epoch 105/120\n",
      " - 2s - loss: 0.4282 - val_loss: 0.5441\n",
      "Epoch 106/120\n",
      " - 2s - loss: 0.4431 - val_loss: 0.4569\n",
      "Epoch 107/120\n",
      " - 2s - loss: 0.3955 - val_loss: 0.4844\n",
      "Epoch 108/120\n",
      " - 2s - loss: 0.3768 - val_loss: 0.4975\n",
      "Epoch 109/120\n",
      " - 2s - loss: 0.3909 - val_loss: 0.5679\n",
      "Epoch 110/120\n",
      " - 2s - loss: 0.3952 - val_loss: 0.5463\n",
      "Epoch 111/120\n",
      " - 2s - loss: 0.3625 - val_loss: 0.5183\n",
      "Epoch 112/120\n",
      " - 2s - loss: 0.3840 - val_loss: 0.5041\n",
      "Epoch 113/120\n",
      " - 2s - loss: 0.3735 - val_loss: 0.4850\n",
      "Epoch 114/120\n",
      " - 2s - loss: 0.3777 - val_loss: 0.5141\n",
      "Epoch 115/120\n",
      " - 2s - loss: 0.3936 - val_loss: 0.5522\n",
      "Epoch 116/120\n",
      " - 2s - loss: 0.3658 - val_loss: 0.5210\n",
      "Epoch 117/120\n",
      " - 2s - loss: 0.3612 - val_loss: 0.4908\n",
      "Epoch 118/120\n",
      " - 2s - loss: 0.3575 - val_loss: 0.5362\n",
      "Epoch 119/120\n",
      " - 2s - loss: 0.3549 - val_loss: 0.4686\n",
      "Epoch 120/120\n",
      " - 2s - loss: 0.3568 - val_loss: 0.5600\n",
      "CPU times: user 16min 59s, sys: 5min 14s, total: 22min 13s\n",
      "Wall time: 19min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_splits=5\n",
    "kfold = StratifiedKFold(n_splits=n_splits, random_state=10, shuffle=True)\n",
    "y_test = np.zeros((X_test_for_nn.shape[0],9*n_splits))\n",
    "train_preds = np.zeros((X_train_for_nn.shape[0],9))\n",
    "X = X_train_for_nn\n",
    "X_test = X_test_for_nn\n",
    "Y = np.array(list(y_train_data[\"surface\"]))\n",
    "for i, (train_index, valid_index) in enumerate(kfold.split(X, Y)):\n",
    "    X_train, X_val =  X[list(train_index),:,:],X[list(valid_index),:,:]\n",
    "    X_train_feat, X_val_feat = X_train_features[list(train_index),:],X_train_features[list(valid_index),:]\n",
    "    Y_train, Y_val = Y[list(train_index)], Y[list(valid_index)]\n",
    "    Y_train = to_categorical(le.transform(Y_train))\n",
    "    Y_val = to_categorical(le.transform(Y_val))\n",
    "    model = LSTM_NN(0.15)\n",
    "    model.fit([X_train,X_train_feat], Y_train, epochs=120, validation_data=([X_val,X_val_feat], Y_val), verbose=2) \n",
    "    y_pred = model.predict([X_val,X_val_feat], verbose=2)\n",
    "    y_test[:,i*9:(i+1)*9] = model.predict([X_test,X_test_features])\n",
    "    train_preds[list(valid_index),:] = np.squeeze(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CV score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score 0.8155\n"
     ]
    }
   ],
   "source": [
    "res_train = np.argmax(train_preds,axis=1)\n",
    "ans_train = np.argmax(to_categorical(le.transform(Y)),axis=1)\n",
    "print (\"CV score\",round(accuracy_score(res_train,ans_train),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exctracting test prediction (most frequent)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "076b8bba1b9f0ff5c80e918c6e68d107c386811e"
   },
   "outputs": [],
   "source": [
    "def most_frequent(List): \n",
    "    occurence_count = Counter(List) \n",
    "    return occurence_count.most_common(1)[0][0]\n",
    "\n",
    "res_test_inter = np.zeros((y_test.shape[0],n_splits))\n",
    "res_test=[]\n",
    "for i in range(n_splits):\n",
    "    inter_arr = y_test[:,i*9:(i+1)*9]\n",
    "    res_test_inter[:,i] = np.argmax(inter_arr,axis=1)\n",
    "for j in range(y_test.shape[0]):\n",
    "    res_test.append(int(most_frequent(res_test_inter[j,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "be2dd318e2fd1dcbb8b9732b0755073b8570a35e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tiled' 'carpet' 'tiled' 'carpet' 'soft_tiles']\n"
     ]
    }
   ],
   "source": [
    "test_for_sub=le.inverse_transform(res_test)\n",
    "print (test_for_sub[:5])\n",
    "test_size = len(list(set(X_test_data[\"series_id\"])))\n",
    "Y_test_pred_array = np.zeros((test_size,2))\n",
    "Y_test_for_submission = pd.DataFrame(Y_test_pred_array,columns = [\"series_id\",\"surface\"])\n",
    "Y_test_for_submission.iloc[:,0] = list(range(test_size))\n",
    "Y_test_for_submission.iloc[:,1] = test_for_sub\n",
    "Y_test_for_submission.to_csv(\"submission.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission.csv' target='_blank'>submission.csv</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/submission.csv"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
