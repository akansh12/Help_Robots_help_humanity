{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['y_train.csv', 'sample_submission.csv', 'X_test.csv', 'X_train.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "a8d43e5d150f7567e77c25610403fd9372c7f76b"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(487680, 13)\n",
      "(488448, 13)\n",
      "(3810, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>measurement_number</th>\n",
       "      <th>orientation_X</th>\n",
       "      <th>orientation_Y</th>\n",
       "      <th>orientation_Z</th>\n",
       "      <th>orientation_W</th>\n",
       "      <th>angular_velocity_X</th>\n",
       "      <th>angular_velocity_Y</th>\n",
       "      <th>angular_velocity_Z</th>\n",
       "      <th>linear_acceleration_X</th>\n",
       "      <th>linear_acceleration_Y</th>\n",
       "      <th>linear_acceleration_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.75853</td>\n",
       "      <td>-0.63435</td>\n",
       "      <td>-0.10488</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>0.107650</td>\n",
       "      <td>0.017561</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>-0.74857</td>\n",
       "      <td>2.1030</td>\n",
       "      <td>-9.7532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.75853</td>\n",
       "      <td>-0.63434</td>\n",
       "      <td>-0.10490</td>\n",
       "      <td>-0.10600</td>\n",
       "      <td>0.067851</td>\n",
       "      <td>0.029939</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.33995</td>\n",
       "      <td>1.5064</td>\n",
       "      <td>-9.4128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.75853</td>\n",
       "      <td>-0.63435</td>\n",
       "      <td>-0.10492</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.028934</td>\n",
       "      <td>-0.005978</td>\n",
       "      <td>-0.26429</td>\n",
       "      <td>1.5922</td>\n",
       "      <td>-8.7267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.75852</td>\n",
       "      <td>-0.63436</td>\n",
       "      <td>-0.10495</td>\n",
       "      <td>-0.10597</td>\n",
       "      <td>-0.013053</td>\n",
       "      <td>0.019448</td>\n",
       "      <td>-0.008974</td>\n",
       "      <td>0.42684</td>\n",
       "      <td>1.0993</td>\n",
       "      <td>-10.0960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.75852</td>\n",
       "      <td>-0.63435</td>\n",
       "      <td>-0.10495</td>\n",
       "      <td>-0.10596</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>-0.50969</td>\n",
       "      <td>1.4689</td>\n",
       "      <td>-10.4410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id          ...            linear_acceleration_Z\n",
       "0    0_0          ...                          -9.7532\n",
       "1    0_1          ...                          -9.4128\n",
       "2    0_2          ...                          -8.7267\n",
       "3    0_3          ...                         -10.0960\n",
       "4    0_4          ...                         -10.4410\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pd.read_csv(\"../input/X_train.csv\")\n",
    "print(x_train.shape)\n",
    "x_test = pd.read_csv(\"../input/X_test.csv\")\n",
    "print(x_test.shape)\n",
    "y_train = pd.read_csv(\"../input/y_train.csv\")\n",
    "print(y_train.shape)\n",
    "\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "7498bf996ce9eb63276d8689a52b42ea9acf999c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3810/3810 [00:06<00:00, 550.30it/s]\n",
      "100%|██████████| 3816/3816 [00:07<00:00, 540.74it/s]\n"
     ]
    }
   ],
   "source": [
    "train_seq = []\n",
    "test_seq = []\n",
    "\n",
    "for i in tqdm(sorted(x_train['series_id'].unique())) :\n",
    "    train_seq.append(x_train[x_train['series_id']==i].drop(['row_id', 'series_id', 'measurement_number'], axis = 1).values)\n",
    "    \n",
    "for i in tqdm(sorted(x_test['series_id'].unique())) :\n",
    "    test_seq.append(x_test[x_test['series_id']==i].drop(['row_id', 'series_id', 'measurement_number'], axis = 1).values)\n",
    "    \n",
    "train_seq = np.array(train_seq)\n",
    "test_seq = np.array(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "f406e6c9bd870635d541ac3ace3de509c4e19d02"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.callbacks import *\n",
    "\n",
    "# https://www.kaggle.com/suicaokhoailang/lstm-attention-baseline-0-652-lb\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim\n",
    "\n",
    "def get_model(input_shape, class_num) :\n",
    "    inp = Input((input_shape[1], input_shape[2]))\n",
    "    x = Bidirectional(CuDNNGRU(128, return_sequences = True))(inp)\n",
    "    x = Bidirectional(CuDNNGRU(64, return_sequences = True))(x)\n",
    "    x = Attention(input_shape[1])(x)\n",
    "    x = Dense(64, activation=\"relu\")(x)\n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "    x = Dense(class_num, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "43c2d8913466d5f0a044cf8a51561e8f112221dd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_num = y_train['surface'].unique().shape[0]\n",
    "y_group = y_train['group_id'].values\n",
    "y_train = pd.get_dummies(y_train['surface'])\n",
    "label_name = [col for col in y_train.columns]\n",
    "y_train = y_train.values\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "random_seed = 2019\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "fold = StratifiedKFold(5, shuffle = True, random_state = random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "99271e01d6456d7e2d71864ab228c5c5fe238fd5",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3044 samples, validate on 766 samples\n",
      "Epoch 1/100\n",
      "3044/3044 [==============================] - 6s 2ms/step - loss: 1.8814 - acc: 0.2911 - val_loss: 1.6856 - val_acc: 0.4021\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.40209, saving model to best_weight.wt\n",
      "Epoch 2/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 1.5782 - acc: 0.4047 - val_loss: 1.5469 - val_acc: 0.4243\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.40209 to 0.42428, saving model to best_weight.wt\n",
      "Epoch 3/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 1.3997 - acc: 0.4908 - val_loss: 1.3758 - val_acc: 0.4739\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.42428 to 0.47389, saving model to best_weight.wt\n",
      "Epoch 4/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 1.2584 - acc: 0.5266 - val_loss: 1.3215 - val_acc: 0.5013\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.47389 to 0.50131, saving model to best_weight.wt\n",
      "Epoch 5/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 1.1427 - acc: 0.5788 - val_loss: 1.1895 - val_acc: 0.5601\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.50131 to 0.56005, saving model to best_weight.wt\n",
      "Epoch 6/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 1.0368 - acc: 0.6101 - val_loss: 1.0585 - val_acc: 0.6123\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.56005 to 0.61227, saving model to best_weight.wt\n",
      "Epoch 7/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.9682 - acc: 0.6386 - val_loss: 0.9560 - val_acc: 0.6684\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.61227 to 0.66841, saving model to best_weight.wt\n",
      "Epoch 8/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.8929 - acc: 0.6646 - val_loss: 0.9504 - val_acc: 0.6488\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.66841\n",
      "Epoch 9/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.8244 - acc: 0.7011 - val_loss: 0.8600 - val_acc: 0.6880\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.66841 to 0.68799, saving model to best_weight.wt\n",
      "Epoch 10/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.7639 - acc: 0.7158 - val_loss: 0.8124 - val_acc: 0.7154\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.68799 to 0.71540, saving model to best_weight.wt\n",
      "Epoch 11/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.6900 - acc: 0.7546 - val_loss: 0.7694 - val_acc: 0.7193\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.71540 to 0.71932, saving model to best_weight.wt\n",
      "Epoch 12/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.6650 - acc: 0.7592 - val_loss: 0.7692 - val_acc: 0.7115\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.71932\n",
      "Epoch 13/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.5912 - acc: 0.7881 - val_loss: 0.7142 - val_acc: 0.7585\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.71932 to 0.75849, saving model to best_weight.wt\n",
      "Epoch 14/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.5822 - acc: 0.7871 - val_loss: 0.7071 - val_acc: 0.7493\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.75849\n",
      "Epoch 15/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.4936 - acc: 0.8246 - val_loss: 0.6719 - val_acc: 0.7559\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.75849\n",
      "Epoch 16/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.4700 - acc: 0.8298 - val_loss: 0.7215 - val_acc: 0.7559\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.75849\n",
      "Epoch 17/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.4690 - acc: 0.8279 - val_loss: 0.7589 - val_acc: 0.7376\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.75849\n",
      "Epoch 18/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.4094 - acc: 0.8453 - val_loss: 0.6132 - val_acc: 0.7977\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.75849 to 0.79765, saving model to best_weight.wt\n",
      "Epoch 19/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.3492 - acc: 0.8771 - val_loss: 0.6037 - val_acc: 0.7911\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.79765\n",
      "Epoch 20/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.3324 - acc: 0.8811 - val_loss: 0.5565 - val_acc: 0.8198\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.79765 to 0.81984, saving model to best_weight.wt\n",
      "Epoch 21/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.2872 - acc: 0.9024 - val_loss: 0.5757 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.81984\n",
      "Epoch 22/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.2916 - acc: 0.8975 - val_loss: 0.5646 - val_acc: 0.8264\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.81984 to 0.82637, saving model to best_weight.wt\n",
      "Epoch 23/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.2673 - acc: 0.9054 - val_loss: 0.6048 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.82637\n",
      "Epoch 24/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.2406 - acc: 0.9156 - val_loss: 0.5873 - val_acc: 0.8172\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.82637\n",
      "Epoch 25/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.1885 - acc: 0.9373 - val_loss: 0.5648 - val_acc: 0.8211\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.82637\n",
      "Epoch 26/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.1615 - acc: 0.9537 - val_loss: 0.6404 - val_acc: 0.8107\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.82637\n",
      "Epoch 27/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.1700 - acc: 0.9435 - val_loss: 0.6078 - val_acc: 0.8290\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.82637 to 0.82898, saving model to best_weight.wt\n",
      "Epoch 28/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.2235 - acc: 0.9218 - val_loss: 0.7001 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.82898\n",
      "Epoch 29/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.1725 - acc: 0.9445 - val_loss: 0.5507 - val_acc: 0.8355\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.82898 to 0.83551, saving model to best_weight.wt\n",
      "Epoch 30/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.1042 - acc: 0.9688 - val_loss: 0.6055 - val_acc: 0.8238\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.83551\n",
      "Epoch 31/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.1040 - acc: 0.9708 - val_loss: 0.6800 - val_acc: 0.8172\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.83551\n",
      "Epoch 32/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0960 - acc: 0.9747 - val_loss: 0.6685 - val_acc: 0.8316\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.83551\n",
      "Epoch 33/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.1021 - acc: 0.9685 - val_loss: 0.6034 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.83551 to 0.84073, saving model to best_weight.wt\n",
      "Epoch 34/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0928 - acc: 0.9721 - val_loss: 0.6177 - val_acc: 0.8420\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.84073 to 0.84204, saving model to best_weight.wt\n",
      "Epoch 35/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0867 - acc: 0.9750 - val_loss: 0.6287 - val_acc: 0.8342\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.84204\n",
      "Epoch 36/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0786 - acc: 0.9754 - val_loss: 0.6635 - val_acc: 0.8381\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.84204\n",
      "Epoch 37/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0892 - acc: 0.9717 - val_loss: 0.6242 - val_acc: 0.8460\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.84204 to 0.84595, saving model to best_weight.wt\n",
      "Epoch 38/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0630 - acc: 0.9842 - val_loss: 0.5887 - val_acc: 0.8551\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.84595 to 0.85509, saving model to best_weight.wt\n",
      "Epoch 39/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0491 - acc: 0.9872 - val_loss: 0.6555 - val_acc: 0.8460\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.85509\n",
      "Epoch 40/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0514 - acc: 0.9869 - val_loss: 0.6291 - val_acc: 0.8486\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.85509\n",
      "Epoch 41/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0605 - acc: 0.9816 - val_loss: 0.8286 - val_acc: 0.7924\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.85509\n",
      "Epoch 42/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.1272 - acc: 0.9589 - val_loss: 0.7712 - val_acc: 0.8277\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.85509\n",
      "Epoch 43/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0871 - acc: 0.9727 - val_loss: 0.7525 - val_acc: 0.8316\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.85509\n",
      "Epoch 44/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.1260 - acc: 0.9573 - val_loss: 0.9765 - val_acc: 0.7781\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.85509\n",
      "Epoch 45/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0985 - acc: 0.9652 - val_loss: 0.7430 - val_acc: 0.8211\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.85509\n",
      "Epoch 46/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0325 - acc: 0.9924 - val_loss: 0.6284 - val_acc: 0.8433\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.85509\n",
      "Epoch 47/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0206 - acc: 0.9954 - val_loss: 0.6063 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.85509 to 0.86031, saving model to best_weight.wt\n",
      "Epoch 48/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0177 - acc: 0.9957 - val_loss: 0.6504 - val_acc: 0.8446\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.86031\n",
      "Epoch 49/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0344 - acc: 0.9915 - val_loss: 0.6196 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.86031 to 0.86292, saving model to best_weight.wt\n",
      "Epoch 50/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0136 - acc: 0.9974 - val_loss: 0.6395 - val_acc: 0.8525\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.86292\n",
      "Epoch 51/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0135 - acc: 0.9961 - val_loss: 0.6438 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.86292\n",
      "Epoch 52/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0090 - acc: 0.9987 - val_loss: 0.6660 - val_acc: 0.8525\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.86292\n",
      "Epoch 53/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0175 - acc: 0.9954 - val_loss: 0.6792 - val_acc: 0.8512\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.86292\n",
      "Epoch 54/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0271 - acc: 0.9901 - val_loss: 0.7597 - val_acc: 0.8316\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.86292\n",
      "Epoch 55/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0959 - acc: 0.9701 - val_loss: 0.8520 - val_acc: 0.8146\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.86292\n",
      "Epoch 56/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.1573 - acc: 0.9465 - val_loss: 0.8765 - val_acc: 0.8094\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.86292\n",
      "Epoch 57/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.1238 - acc: 0.9606 - val_loss: 0.8682 - val_acc: 0.8003\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.86292\n",
      "Epoch 58/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.1038 - acc: 0.9648 - val_loss: 0.7287 - val_acc: 0.8446\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.86292\n",
      "Epoch 59/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0335 - acc: 0.9892 - val_loss: 0.6544 - val_acc: 0.8551\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.86292\n",
      "Epoch 60/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0086 - acc: 0.9993 - val_loss: 0.6606 - val_acc: 0.8525\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.86292\n",
      "Epoch 61/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.6507 - val_acc: 0.8551\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.86292\n",
      "Epoch 62/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0056 - acc: 0.9990 - val_loss: 0.6441 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.86292 to 0.86554, saving model to best_weight.wt\n",
      "Epoch 63/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0042 - acc: 0.9993 - val_loss: 0.6802 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.86554\n",
      "Epoch 64/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0045 - acc: 0.9990 - val_loss: 0.6688 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.86554\n",
      "Epoch 65/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.6707 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.86554\n",
      "Epoch 66/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6818 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.86554\n",
      "Epoch 67/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.7074 - val_acc: 0.8564\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.86554\n",
      "Epoch 68/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0727 - acc: 0.9842 - val_loss: 1.0182 - val_acc: 0.7872\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.86554\n",
      "Epoch 69/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.4026 - acc: 0.8830 - val_loss: 0.7555 - val_acc: 0.8081\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.86554\n",
      "Epoch 70/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0746 - acc: 0.9757 - val_loss: 0.6727 - val_acc: 0.8394\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.86554\n",
      "Epoch 71/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0261 - acc: 0.9957 - val_loss: 0.6376 - val_acc: 0.8525\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.86554\n",
      "Epoch 72/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0111 - acc: 0.9987 - val_loss: 0.6362 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.86554\n",
      "Epoch 73/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0051 - acc: 0.9997 - val_loss: 0.6412 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.86554\n",
      "Epoch 74/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.6440 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.86554\n",
      "Epoch 75/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.6507 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.86554\n",
      "Epoch 76/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.6581 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.86554\n",
      "Epoch 77/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.6614 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.86554\n",
      "Epoch 78/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.6671 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.86554\n",
      "Epoch 79/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.6766 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.86554\n",
      "Epoch 80/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.6804 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.86554\n",
      "Epoch 81/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.6873 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.86554\n",
      "Epoch 82/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.6900 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.86554\n",
      "Epoch 83/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.6947 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.86554\n",
      "Epoch 84/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.7047 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.86554\n",
      "Epoch 85/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.7041 - val_acc: 0.8590\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.86554\n",
      "Epoch 86/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 9.5282e-04 - acc: 1.0000 - val_loss: 0.7119 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.86554\n",
      "Epoch 87/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 8.7893e-04 - acc: 1.0000 - val_loss: 0.7160 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.86554\n",
      "Epoch 88/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 8.1000e-04 - acc: 1.0000 - val_loss: 0.7184 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.86554\n",
      "Epoch 89/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 7.4907e-04 - acc: 1.0000 - val_loss: 0.7236 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.86554\n",
      "Epoch 90/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 7.1992e-04 - acc: 1.0000 - val_loss: 0.7272 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.86554\n",
      "Epoch 91/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 6.6046e-04 - acc: 1.0000 - val_loss: 0.7319 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.86554\n",
      "Epoch 92/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 6.0067e-04 - acc: 1.0000 - val_loss: 0.7368 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.86554\n",
      "Epoch 93/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 5.6454e-04 - acc: 1.0000 - val_loss: 0.7404 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.86554\n",
      "Epoch 94/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 5.2459e-04 - acc: 1.0000 - val_loss: 0.7434 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.86554\n",
      "Epoch 95/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 5.0122e-04 - acc: 1.0000 - val_loss: 0.7491 - val_acc: 0.8590\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.86554\n",
      "Epoch 96/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 4.6112e-04 - acc: 1.0000 - val_loss: 0.7524 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.86554\n",
      "Epoch 97/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 4.3337e-04 - acc: 1.0000 - val_loss: 0.7586 - val_acc: 0.8564\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.86554\n",
      "Epoch 98/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 4.0165e-04 - acc: 1.0000 - val_loss: 0.7606 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.86554\n",
      "Epoch 99/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 3.7840e-04 - acc: 1.0000 - val_loss: 0.7625 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.86554\n",
      "Epoch 100/100\n",
      "3044/3044 [==============================] - 3s 1ms/step - loss: 3.5444e-04 - acc: 1.0000 - val_loss: 0.7684 - val_acc: 0.8603\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.86554\n",
      "Train on 3045 samples, validate on 765 samples\n",
      "Epoch 1/100\n",
      "3045/3045 [==============================] - 4s 1ms/step - loss: 1.9833 - acc: 0.2535 - val_loss: 1.7782 - val_acc: 0.3556\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.35556, saving model to best_weight.wt\n",
      "Epoch 2/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 1.6077 - acc: 0.4053 - val_loss: 1.5055 - val_acc: 0.4366\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.35556 to 0.43660, saving model to best_weight.wt\n",
      "Epoch 3/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 1.4275 - acc: 0.4709 - val_loss: 1.3266 - val_acc: 0.4667\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.43660 to 0.46667, saving model to best_weight.wt\n",
      "Epoch 4/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 1.3182 - acc: 0.5166 - val_loss: 1.2601 - val_acc: 0.5333\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.46667 to 0.53333, saving model to best_weight.wt\n",
      "Epoch 5/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 1.2179 - acc: 0.5563 - val_loss: 1.0888 - val_acc: 0.5935\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.53333 to 0.59346, saving model to best_weight.wt\n",
      "Epoch 6/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 1.1177 - acc: 0.5878 - val_loss: 1.0941 - val_acc: 0.6078\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.59346 to 0.60784, saving model to best_weight.wt\n",
      "Epoch 7/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 1.0159 - acc: 0.6404 - val_loss: 0.9220 - val_acc: 0.6719\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.60784 to 0.67190, saving model to best_weight.wt\n",
      "Epoch 8/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.9439 - acc: 0.6598 - val_loss: 0.9452 - val_acc: 0.6536\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.67190\n",
      "Epoch 9/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.8836 - acc: 0.6670 - val_loss: 0.8604 - val_acc: 0.6837\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.67190 to 0.68366, saving model to best_weight.wt\n",
      "Epoch 10/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.8036 - acc: 0.7054 - val_loss: 0.7621 - val_acc: 0.7346\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.68366 to 0.73464, saving model to best_weight.wt\n",
      "Epoch 11/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.7308 - acc: 0.7376 - val_loss: 0.7344 - val_acc: 0.7294\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.73464\n",
      "Epoch 12/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.6602 - acc: 0.7534 - val_loss: 0.6898 - val_acc: 0.7542\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.73464 to 0.75425, saving model to best_weight.wt\n",
      "Epoch 13/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.6332 - acc: 0.7787 - val_loss: 0.7291 - val_acc: 0.7542\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.75425\n",
      "Epoch 14/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.5536 - acc: 0.8069 - val_loss: 0.6468 - val_acc: 0.7686\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.75425 to 0.76863, saving model to best_weight.wt\n",
      "Epoch 15/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.5314 - acc: 0.8138 - val_loss: 0.6213 - val_acc: 0.7830\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.76863 to 0.78301, saving model to best_weight.wt\n",
      "Epoch 16/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.4761 - acc: 0.8440 - val_loss: 0.6477 - val_acc: 0.7725\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.78301\n",
      "Epoch 17/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.4220 - acc: 0.8621 - val_loss: 0.6126 - val_acc: 0.7895\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.78301 to 0.78954, saving model to best_weight.wt\n",
      "Epoch 18/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.4219 - acc: 0.8535 - val_loss: 0.6045 - val_acc: 0.7961\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.78954 to 0.79608, saving model to best_weight.wt\n",
      "Epoch 19/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.3723 - acc: 0.8696 - val_loss: 0.5495 - val_acc: 0.8105\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.79608 to 0.81046, saving model to best_weight.wt\n",
      "Epoch 20/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.3452 - acc: 0.8913 - val_loss: 0.6231 - val_acc: 0.7948\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.81046\n",
      "Epoch 21/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.3100 - acc: 0.8851 - val_loss: 0.5884 - val_acc: 0.8065\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.81046\n",
      "Epoch 22/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.3042 - acc: 0.8966 - val_loss: 0.5674 - val_acc: 0.8196\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.81046 to 0.81961, saving model to best_weight.wt\n",
      "Epoch 23/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.2363 - acc: 0.9215 - val_loss: 0.5629 - val_acc: 0.8235\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.81961 to 0.82353, saving model to best_weight.wt\n",
      "Epoch 24/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.2002 - acc: 0.9373 - val_loss: 0.5872 - val_acc: 0.8196\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.82353\n",
      "Epoch 25/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.2023 - acc: 0.9291 - val_loss: 0.5721 - val_acc: 0.8301\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.82353 to 0.83007, saving model to best_weight.wt\n",
      "Epoch 26/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.2185 - acc: 0.9307 - val_loss: 0.6337 - val_acc: 0.8078\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.83007\n",
      "Epoch 27/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.1692 - acc: 0.9498 - val_loss: 0.6150 - val_acc: 0.8235\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.83007\n",
      "Epoch 28/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.2039 - acc: 0.9343 - val_loss: 0.5861 - val_acc: 0.8379\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.83007 to 0.83791, saving model to best_weight.wt\n",
      "Epoch 29/100\n",
      "3045/3045 [==============================] - 3s 1ms/step - loss: 0.1329 - acc: 0.9619 - val_loss: 0.6797 - val_acc: 0.8301\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.83791\n",
      "Epoch 30/100\n",
      "  96/3045 [..............................] - ETA: 3s - loss: 0.1831 - acc: 0.9271"
     ]
    }
   ],
   "source": [
    "oof_train = np.zeros((train_seq.shape[0], class_num))\n",
    "oof_test = np.zeros((test_seq.shape[0], class_num))\n",
    "\n",
    "for i, (trn, val) in enumerate(list(fold.split(y_train, np.argmax(y_train, axis = 1)))) :\n",
    "    model = get_model(train_seq.shape, class_num)\n",
    "    chk = ModelCheckpoint(\"best_weight.wt\", monitor='val_acc', mode = 'max', save_best_only = True, verbose = 1)\n",
    "    model.fit(train_seq[trn], y_train[trn]\n",
    "             , epochs = 100, batch_size = 32\n",
    "             , validation_data = [train_seq[val], y_train[val]]\n",
    "             , callbacks = [chk])\n",
    "    model.load_weights(\"best_weight.wt\")\n",
    "    oof_train[val] = model.predict(train_seq[val])\n",
    "    oof_test += model.predict(test_seq) / fold.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "abc3acf73a3ebde0dccd4deba290567cdc305eff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>surface</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hard_tiles_large_space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>carpet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fine_concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>wood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>soft_pvc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   series_id                 surface\n",
       "0          0  hard_tiles_large_space\n",
       "1          1                  carpet\n",
       "2          2           fine_concrete\n",
       "3          3                    wood\n",
       "4          4                soft_pvc"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "submission['surface'] = pd.DataFrame(np.argmax(oof_test, axis = 1))[0].apply(lambda x : label_name[x]).values.reshape(-1)\n",
    "submission.to_csv(\"submission.csv\", index = False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "b9531f35e0b9d05ee6f93561070fe9dcd50eb86d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8b42b0a358>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"surface\", data=pd.read_csv(\"../input/y_train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "eda1ecd5181570aa26e9b81bb4879ce6b4dcb2bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8b42a510b8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"surface\", data=submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
